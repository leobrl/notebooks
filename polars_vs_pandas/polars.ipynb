{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars VS Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Polars\n",
    "\n",
    "[Polars](https://pola.rs/) is a library written in Rust designed to do efficient data manipulation on a single machine.\n",
    "\n",
    "How is it different from Pandas?\n",
    "\n",
    "One of the key differences is that Pandas is built on top of python libraries, in particular NumPy. While NumPy core is written in C, it is mostly optimized for numeric types, not for string-like data, like categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random dataframe: 1M rows, 2 columns are string, 3 are float / int\n",
    "\n",
    "@dataclass\n",
    "class Column:\n",
    "    name: str\n",
    "    type: type\n",
    "    length: int\n",
    "\n",
    "def random_data_set(columns: list[Column]):\n",
    "    rng = np.random.default_rng()\n",
    "    letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "\n",
    "    data = {}\n",
    "    for column in columns:\n",
    "        col_len = column.length\n",
    "        match column.type.__name__:\n",
    "            case str.__name__:\n",
    "                data[column.name] = [\"\".join(rng.choice(letters, 10)) for _ in range(col_len)]\n",
    "            case float.__name__:\n",
    "                data[column.name] = list(map(float, rng.standard_normal(size=col_len)))\n",
    "            case int.__name__:\n",
    "                data[column.name] = list(map(int, rng.integers(10_000, size=col_len)))\n",
    "            case _:\n",
    "                raise ValueError\n",
    "\n",
    "    return data\n",
    "\n",
    "n = 1_000_000\n",
    "columns = [Column(\"col_1\", str, n), Column(\"col_2\", float, n), Column(\"col_3\", str, n), Column(\"col_4\", float, n), Column(\"col_5\", int, n)]\n",
    "# data = random_data_set(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_it\n",
    "\n",
    "@dataclass\n",
    "class Time:\n",
    "    wall_time: float\n",
    "    cpu_time: float\n",
    "\n",
    "def time_it(n_times: int):\n",
    "    def _time_it(func):\n",
    "        def wrapped(*args, **kwargs):\n",
    "            start, p_start = time.time(), time.process_time()\n",
    "            for _ in range(n_times):\n",
    "                res = func(*args, **kwargs)\n",
    "            end, p_end = time.time(), time.process_time()\n",
    "\n",
    "            return res, Time(end-start, p_end-p_start)\n",
    "\n",
    "        return wrapped\n",
    "    return _time_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing pretty-print\n",
    "def print_timing(res: tuple):\n",
    "    *ret, execution_time = res\n",
    "    print(f\"CPU Execution time: {execution_time} seconds\")\n",
    "    return *ret,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset to load\n",
    "file_name = \"data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=0.5726299285888672, cpu_time=5.2285115000000815) seconds\n"
     ]
    }
   ],
   "source": [
    "# read a large csv in polar\n",
    "@time_it(10)\n",
    "def pl_read_csv(path):\n",
    "    return pl.read_csv(path)\n",
    "\n",
    "pl_df = print_timing(pl_read_csv(file_name))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=15.525216579437256, cpu_time=15.494220399999904) seconds\n"
     ]
    }
   ],
   "source": [
    "# read a large csv in \"naive\" pandas 1- times\n",
    "@time_it(10)\n",
    "def pd_read_csv(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "pd_df_numpy_backend = print_timing(pd_read_csv(file_name))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that the whole story? Nope! Since version 2.0 pandas support (Py)Arrow as well. The \"pyarrow\" engine also support multithreading, which is not supported by the other engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=0.684666633605957, cpu_time=6.8203726000000415) seconds\n"
     ]
    }
   ],
   "source": [
    "# read a large csv in pandas - try again..\n",
    "@time_it(10)\n",
    "def pd_read_csv(path):\n",
    "    return pd.read_csv(path, engine=\"pyarrow\", dtype_backend='pyarrow')\n",
    "\n",
    "pd_df = print_timing(pd_read_csv(file_name))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyarrow are Arrow Python bindings based on the C++ implementation of Apache Arrow. \n",
    "\n",
    "Apache Arrow is a set of specification plust implementation in multiple languages (C++, Rust, Julia, ..) \n",
    "The main characteristics are:\n",
    "1. designed for in-memory analytics: it is optimized to read and write data in memory and to move data around\n",
    "2. designed for tabular data: it optimize memory by having data in the same column (and thus of the same type) near in memory. This allows for optimization like SIMD and cache-missing optimization.\n",
    "3. specification is (by definition) language-agnostic: multiple implementation allow for easy interoperability between code written in different languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most interesting examples that illustrate well the advantage of the Arrow memory layout is how strings are treated in Pandas (see this great article [Apache Arrow and the “10 Things I Hate About pandas”](https://wesmckinney.com/blog/apache-arrow-pandas-internals/)). By default an array of strings is an array of PyObject pointers. This are continuous in memory. What is not though, is the actual string, which lives inside a structure, PyBytes or PyUnicode, allocated in the heap.\n",
    "\n",
    "In Python, the simple string 'wes' occupies 52 bytes of memory. '' occupies 49 bytes. For a great discussion of issues around this, see Jake Vanderplas’s epic exposé on [Why Python is Slow](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index     0.000126\n",
       "col_1    56.266785\n",
       "col_2     7.629395\n",
       "col_3    56.266785\n",
       "col_4     7.629395\n",
       "col_5     7.629395\n",
       "dtype: float64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas memory usage (Mb)\n",
    "mb = 1024 * 1024\n",
    "pd_df_numpy_backend.memory_usage(deep=True)/mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index     0.000126\n",
       "col_1    13.351440\n",
       "col_2     7.629395\n",
       "col_3    13.351440\n",
       "col_4     7.629395\n",
       "col_5     7.629395\n",
       "dtype: float64"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas memory usage with Pyarrow (Mb)\n",
    "pd_df.memory_usage(deep=True) / mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.961669921875"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Polars (estimated) memory usage (Mb)\n",
    "pl_df.estimated_size() / mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=0.26548242568969727, cpu_time=0.5598384999999553) seconds\n"
     ]
    }
   ],
   "source": [
    "# mean with Polars\n",
    "\n",
    "@time_it(100)\n",
    "def calc_pl_mean_by_index(df: pl.DataFrame):\n",
    "    return df.select(pl.all().exclude([\"col_1\", \"col_3\"])).mean()\n",
    "\n",
    "pl_mean = print_timing(calc_pl_mean_by_index(pl_df))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=0.5080535411834717, cpu_time=0.5108791999999767) seconds\n"
     ]
    }
   ],
   "source": [
    "# mean with Pandas\n",
    "\n",
    "@time_it(100)\n",
    "def calc_pd_mean_by_index(df: pd.DataFrame):\n",
    "    return df.drop([\"col_1\", \"col_3\"], axis=1).mean()\n",
    "\n",
    "pd_mean = print_timing(calc_pd_mean_by_index(pd_df))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=1.1078405380249023, cpu_time=2.929636999999957) seconds\n"
     ]
    }
   ],
   "source": [
    "# Groupby with Polars\n",
    "\n",
    "@time_it(100)\n",
    "def calc_pl_mean_close_by_index(df: pl.DataFrame):\n",
    "    return df.filter(pl.col('col_2') > pl.col('col_4').mean())\n",
    "\n",
    "pl_mean_close = print_timing(calc_pl_mean_close_by_index(pl_df))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=3.943446636199951, cpu_time=3.928661899999952) seconds\n"
     ]
    }
   ],
   "source": [
    "# Groupby with Pandas\n",
    "\n",
    "@time_it(100)\n",
    "def calc_pd_mean_close_by_index(df: pd.DataFrame):\n",
    "    return df[df['col_2'] > df['col_4'].mean()]\n",
    "\n",
    "pd_mean_close = print_timing(calc_pd_mean_close_by_index(pd_df))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-trivial op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=1.6172640323638916, cpu_time=1.6198280999999497) seconds\n"
     ]
    }
   ],
   "source": [
    "# Rolling mean with Polars\n",
    "\n",
    "@time_it(100)\n",
    "def calc_pl_ma(df: pl.DataFrame):\n",
    "    return df[\"col_2\"].rolling_mean(window_size=10)\n",
    "\n",
    "pl_ma = print_timing(calc_pl_ma(pl_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=2.4736294746398926, cpu_time=2.47524599999997) seconds\n"
     ]
    }
   ],
   "source": [
    "# Rolling mean with Pandas\n",
    "\n",
    "@time_it(100)\n",
    "def calc_pd_ma(df: pd.DataFrame):\n",
    "    return df[\"col_2\"].rolling(window=10).mean()\n",
    "\n",
    "pd_ma = print_timing(calc_pd_ma(pd_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution time: Time(wall_time=1.1847584247589111, cpu_time=1.1877812000000176) seconds\n"
     ]
    }
   ],
   "source": [
    "# Rolling mean with Numpy\n",
    "\n",
    "@time_it(100)\n",
    "def calc_np__ma(df: pd.DataFrame):\n",
    "    ts = df[\"col_2\"].to_numpy()\n",
    "    window=10\n",
    "    ret = np.cumsum(ts, dtype=float)\n",
    "    ret[window:] = ret[window:] - ret[:-window]\n",
    "    return ret[window - 1:] / window\n",
    "\n",
    "np_ma = print_timing(calc_np__ma(pd_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
